```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(rethinking)
library(brms)
library(loo)
library(dagitty, quietly = TRUE)
library(ggdag, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(ggmcmc, quietly = TRUE)
library(bayesplot, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```


# Counting and Classification {#Counting}



## Binomial regression

### Logistic regression: Prosocial chimpanzees

Load the data


```{r}
data(chimpanzees)
d <- chimpanzees
rm(chimpanzees)
d %>%
  distinct(prosoc_left, condition) %>%
  mutate(treatment = 1 + prosoc_left + 2 * condition,
         description = c("Alone and two food items on the right",
                         "Alone and two food items on the left",
                         "Partner and two food items on the right",
                         "Partner and two food items on the left"))
```

Create a variable `treatment` that is a
code for `prosoc_left` and `condition` variables with the following meanings


```{r}
d <- d %>%
  mutate(actor = factor(actor),
         treatment = factor(1 + prosoc_left + 2 * condition, levels = 1:4, ordered = TRUE),
         labels = factor(treatment, levels = 1:4, labels = c("a/r", "a/l", "p/r", "p/l")),
         side = factor(prosoc_left + 1),
         cond = factor(condition + 1))
skimr::skim(d)
```

The model used will be

$$
\begin{align*}
pulled\_left_i &\sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) &= \alpha_{actor[i]} + \beta_{treatment[i]} \\
\alpha_j &\sim \mathcal{N}(0, sd) \\
\beta_k &\sim \mathcal{N}(0, sd) \\
&\text{sd to be determined}
\end{align*}
$$


#### Prior for $\alpha$


We begin with the one-intercept only model, the "null" model as we can maybe call
it.  It refers to a general mean for all $p_i$.

$$
\begin{align*}
pulled\_left_i &\sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) &= \alpha \\
\alpha &\sim \mathcal{N}(0, 10)
\end{align*}
$$


in `brm( forml = pulled_left | trials(1) ~ 1)` the `|` indicates we have extra
information about the criterion. In this case, that information is that each
`pulled_left` corresponds to a single trial, i.e. `trials(1)` which corresponds
to the $n = 1$ in $Binomial(1, p_i)$

We will use 2 sd values for $\alpha \sim \mathcal{N}(0, sd)$.

```{r}
prior_alpha_sd <- c(10, 1.5)
prior_alpha_sd
```


```{r}
a_file <- here::here("fits", "b11_01.rds")
b11.1 <- readRDS(file = a_file)
# b11.1 <- brm(data = d,
#               family = binomial,
#               formula = pulled_left | trials(1) ~ 1,
#               prior = c(
#                 prior(normal(0, 10), class = Intercept)
#                 ),
#               seed = 11, cores = detectCores(),
#               sample_prior = TRUE
#               )
# b11.1 <- brms::add_criterion(b11.1, criterion = c("waic", "loo"))
# saveRDS(b11.1, file = a_file)
summary(b11.1)
# convert the result using the inverse link funciton,
# in this case the logistic funciton or inv_logit()
brms::inv_logit_scaled(fixef(b11.1))
```

and we convert the result using `brms::inv_logit_scaled()`.

```{r}
brms::inv_logit_scaled(fixef(b11.1))
```

and we use another value for the prior to be able to calibrate it.


$$
\begin{align*}
pulled\_left_i &\sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) &= \alpha \\
\alpha &\sim \mathcal{N}(0, 1.5)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b11_01b.rds")
b11.1b <- readRDS(file = a_file)
# b11.1b <- brm(data = d,
#               family = binomial,
#               formula = pulled_left | trials(1) ~ 1,
#               prior = c(
#                 prior(normal(0, 1.5), class = Intercept)
#                 ),
#               seed = 11, cores = detectCores(),
#               sample_prior = TRUE
#               )
# b11.1b <- brms::add_criterion(b11.1b, criterion = c("waic", "loo"))
# saveRDS(b11.1b, file = a_file)
summary(b11.1b)
brms::inv_logit_scaled(fixef(b11.1b))
```


and we visualize the outcome using the prior samples


```{r}
b11.1_prior <- prior_samples(b11.1)
b11.1b_prior <- prior_samples(b11.1b)
b11.1_prior_df <- bind_rows(b11.1_prior, b11.1b_prior) %>%
  mutate(p = inv_logit_scaled(Intercept),
         id = rep(c("sd = 10", "sd = 1.5"), each = n() / 2))

ggplot(b11.1_prior_df, aes(x = p, fill = id, color = id)) +
  geom_density(aes(y = ..count..), alpha = 3/4) +
  scale_fill_paletteer_d("lisa::PavelTchelitchew") +
  scale_color_paletteer_d("lisa::PavelTchelitchew") +
  ggthemes::theme_gdocs() +
  theme(legend.position = c(0.5, 0.8)) +
  labs(title = "Density of pulled_left with prior",
       subtitle = "Model 11.1 and 11.1b",
       x = "prob. of pulled_left")
```


#### Prior for $\beta_{treatment[i]}$

Now we find the sd value for the prior $\beta_k &\sim \mathcal{N}(0, sd)$.
Note that Solomon Kurtz in @kurtz2020b uses `inv_logit_scaled()` whereas
mcElreath in @elreath2020 uses `inv_logit()`.

$$
\begin{align*}
pulled\_left_i &\sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) &= \alpha + \beta_{treatment[i]} \\
\alpha &\sim \mathcal{N}(0, 1.5) \\
\beta_k &\sim \mathcal{N}(0, sd) \\
&\text{sd to be determined}
\end{align*}
$$

We get the fit with $sd = 10$


```{r}
a_file <- here::here("fits", "b11_02.rds")
b11.2 <- readRDS(file = a_file)
# b11.2 <- brm(data = d,
#               family = binomial,
#               formula = bf(pulled_left | trials(1) ~ a + b,
#                            a ~ 1,
#                            b ~ 0 + treatment,
#                            nl = TRUE),
#               prior = c(
#                 prior(normal(0, 1.5), nlpar = a),
#                 prior(normal(0, 10), nlpar = b, coef = treatment1),
#                 prior(normal(0, 10), nlpar = b, coef = treatment2),
#                 prior(normal(0, 10), nlpar = b, coef = treatment3),
#                 prior(normal(0, 10), nlpar = b, coef = treatment4)
#                 ),
#               sample_prior = TRUE,
#              cores = detectCores(), seed = 11)
# b11.2 <- brms::add_criterion(b11.2, criterion = c("waic", "loo"))
# saveRDS(b11.2, file = a_file)
summary(b11.2)
brms::inv_logit_scaled(fixef(b11.2))
```



then the fit with $sd = 0.5$

```{r}
a_file <- here::here("fits", "b11_03.rds")
b11.3 <- readRDS(file = a_file)
# b11.3 <- brm(data = d,
#               family = binomial,
#               formula = bf(pulled_left | trials(1) ~ a + b,
#                            a ~ 1,
#                            b ~ 0 + treatment,
#                            nl = TRUE),
#               prior = c(
#                 prior(normal(0, 1.5), nlpar = a),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment1),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment2),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment3),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment4)
#                 ),
#               sample_prior = TRUE,
#              cores = detectCores(), seed = 11)
# b11.3 <- brms::add_criterion(b11.3, criterion = c("waic", "loo"))
# saveRDS(b11.3, file = a_file)
summary(b11.3)
brms::inv_logit_scaled(fixef(b11.3))
```

```{r}
b11.2_prior <- prior_samples(b11.2)
b11.3_prior <- prior_samples(b11.3)

b11.2_prior_df <- bind_rows(b11.2_prior, b11.3_prior) %>%
  mutate(p1 = inv_logit_scaled(b_a + b_b_treatment1),
         p2 = inv_logit_scaled(b_a + b_b_treatment2),
         diff = abs(p1 - p2),
         id = rep(c("sd = 10", "sd = 0.5"), each = n() / 2))

ggplot(b11.2_prior_df, aes(x = diff, fill = id, color = id)) +
  geom_density(aes(y = ..count..), alpha = 3/4) +
  scale_fill_paletteer_d("lisa::BarnettNewman", direction = 1) +
  scale_color_paletteer_d("lisa::BarnettNewman", direction = 1) +
  ggthemes::theme_gdocs() +
  theme(legend.position = c(0.5, 0.8)) +
  labs(title = "Density of difference: pulled_left with prior",
       subtitle = "Model 11.2 and 11.3",
       x = "prob. of pulled_left")
```

#### The full model

Now that we have investigated the prior, let's do the full model with them


$$
\begin{align*}
pulled\_left_i &\sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) &= \alpha_{actor[i]} + \beta_{treatment[i]} \\
\alpha_j &\sim \mathcal{N}(0, 1.5) \\
\beta_k &\sim \mathcal{N}(0, 0.5)
\end{align*}
$$



```{r}
a_file <- here::here("fits", "b11_04.rds")
b11.4 <- readRDS(file = a_file)
# b11.4 <- brm(data = d,
#               family = binomial,
#               formula = bf(pulled_left | trials(1) ~ a + b,
#                            a ~ 0 + actor,
#                            b ~ 0 + treatment,
#                            nl = TRUE),
#               prior = c(
#                 prior(normal(0, 1.5), nlpar = a),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment1),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment2),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment3),
#                 prior(normal(0, 0.5), nlpar = b, coef = treatment4)
#                 ),
#              cores = detectCores(), seed = 11)
# b11.4 <- brms::add_criterion(b11.4, criterion = c("waic", "loo"))
# saveRDS(b11.4, file = a_file)
summary(b11.4)
brms::inv_logit_scaled(fixef(b11.4))
```

```{r}
get_variables(b11.4)
```

for the coefficients related to actors we have

```{r}
# NOTE: do not do actors and treatments together because of inv_logit_scaled
df <- posterior_samples(b11.4) %>%
  select(starts_with("b_a_")) %>%
  pivot_longer(cols = everything(), names_to = "actor") %>%
  mutate(prob = brms::inv_logit_scaled(value),
         id = factor(gsub(pattern = "^b_a_", replacement = "", x = actor))) %>%
  group_by(id) %>%
  ggdist::mean_qi(prob, .width = 0.95)
# glimpse(df)


ggplot(df, aes(x = prob, y = id)) +
  geom_pointintervalh(color = "darkgreen") +
  ggrepel::geom_text_repel(aes(label = round(prob, 2)), size = 3) +
  # theme_minimal() +
  ggthemes::theme_hc() +
  theme(title = element_text(color = "midnightblue")
        ) +
  labs(title = "probability (logistic / inv_logit) coefficient for actors",
       subtitle = "Model b11.4",
       x = "probability / proportion of time", y = NULL)
```

and for treatment

```{r}
get_variables(b11.4)
```

```{r}
df <- posterior_samples(b11.4) %>%
  select(starts_with("b_b_")) %>%
  pivot_longer(cols = everything(), names_to = "treatment") %>%
  mutate(prob = brms::inv_logit_scaled(value),
         id = gsub(pattern = "^b_b_", replacement = "", x = treatment),
         label = case_when(
           treatment == "b_b_treatment1" ~ "A/R",
           treatment == "b_b_treatment2" ~ "A/L",
           treatment == "b_b_treatment3" ~ "P/R",
           treatment == "b_b_treatment4" ~ "P/L",
           TRUE ~ as.character(treatment)
         )) %>%
  group_by(label) %>%
  ggdist::mean_qi(value, .width = 0.95)
# glimpse(df)

ggplot(df, aes(x = value, y = label)) +
  geom_pointintervalh(color = "goldenrod") +
  ggrepel::geom_text_repel(aes(label = round(value, 2)), size = 3) +
  ggthemes::theme_hc() +
  theme(title = element_text(color = "midnightblue")
        ) +
  labs(title = "logit coefficient for treatments",
       subtitle = "Model b11.4",
       x = "logit", y = NULL)
```


to compare the models

```{r}
w <- loo_compare(b11.2, b11.3, b11.4, criterion = "waic") %>%
  as.data.frame() %>%
  mutate(waic_diff = elpd_diff * -2,
         waic_diff_se = se_diff * 2) %>%
  round(digits = 1) %>%
  tibble::rownames_to_column(var = "model")
print(w, simplify = FALSE)
```

and the coefficient plot is

```{r}
ggplot(w, aes(x = reorder(model, waic), color = model)) +
  geom_pointrange(aes(y = waic, ymin = waic - se_waic, ymax = waic+ se_waic)) +
  coord_flip() +
  ggthemes::theme_clean() +
  theme(legend.position = "none") +
  labs(title = "WAIC", y = "deviance", x = "model")
```


### Relative shark and absolute deer

```{r}
posterior_samples(b11.4) %>% 
  mutate(proportional_odds = exp(b_b_treatment4 - b_b_treatment2)) %>% 
  mean_qi(proportional_odds)
```

On average the switch from treatment 2 to treatment 4 multiply the odds of pulling
tthe left lever by 92%.

> The risk of focusing on relative effects, such as proportional odds, is that
they aren't enough to tell enough whether a variable is important or not.

See the ovethinking box in section 11.1.2, p. 337.

### Aggregated binomial: Chimpanzees again


```{r}
d.aggr <- d %>%
  group_by(treatment, actor, side, cond) %>%
  summarise(left_pulls = sum(pulled_left)) %>%
  ungroup()
d.aggr
```

```{r}
a_file <- here::here("fits", "b11_06.rds")
b11.6 <- readRDS(file = a_file)
# b11.6 <- brms::brm(
#   data = d.aggr,
#   family = binomial,
#   formula = bf(left_pulls | trials(18) ~ a + b,
#                a ~ 0 + actor, 
#                b ~ 0 + treatment,
#                nl = TRUE),
#   prior =  c(prior(normal(0, 1.5), nlpar = a),
#              prior(normal(0, 0.5), nlpar = b)),
#   cores = detectCores(), seed = 11
#   )
# b11.6 <- brms::add_criterion(b11.6, criterion = c("waic", "loo"))
# saveRDS(b11.6, file = a_file)
summary(b11.6)
brms::inv_logit_scaled(fixef(b11.6))
```


### Aggregated binomial: Graduate school admissions

In the chimpanzees example, the number of trials was fixed at 18.  This is
often not the case.


```{r}
data(UCBadmit)
d <- UCBadmit %>%
  mutate(gid = factor(applicant.gender, levels = c("male", "female")),
         case = seq_len(nrow(.)))
rm(UCBadmit)
skimr::skim(d)
```


the univariate model is

$$
\begin{align*}
admit_i &\sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) &= \alpha_{gid[i]} \\
\alpha_j &\sim \mathcal{N}(0, 1.5)
\end{align*}
$$
and we fit the model

```{r}
a_file <- here::here("fits", "b11_07.rds")
b11.7 <- readRDS(a_file)
# b11.7 <- brm(data = d, 
#       family = binomial,
#       admit | trials(applications) ~ 0 + gid,
#       prior(normal(0, 1.5), class = b),
#       cores = detectCores(), seed = 11)
# b11.7 <- brms::add_criterion(b11.7, criterion = c("waic", "loo"))
# saveRDS(b11.7, file = a_file)
summary(b11.7)
brms::inv_logit_scaled(fixef(b11.7))
```



and the full model is

$$
\begin{align*}
admit_i &\sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) &= \alpha_{gid[i]} + \delta_{dept[i]} \\
\alpha_j &\sim \mathcal{N}(0, 1.5) \\
\delta_k &\sim \mathcal{N}(0, 1.5)
\end{align*}
$$
and we fit the model

```{r}
a_file <- here::here("fits", "b11_08.rds")
b11.8 <- readRDS(a_file)
# b11.8 <- brm(data = d, 
#       family = binomial,
#       bf(admit | trials(applications) ~ a + d,
#          a ~ 0 + gid, 
#          d ~ 0 + dept,
#          nl = TRUE),
#       prior = c(prior(normal(0, 1.5), nlpar = a),
#                 prior(normal(0, 1.5), nlpar = d)),
#       iter = 4000, warmup = 1000, cores = detectCores(), seed = 11)
# b11.8 <- brms::add_criterion(b11.8, criterion = c("waic", "loo"))
# saveRDS(b11.8, file = a_file)
summary(b11.8)
brms::inv_logit_scaled(fixef(b11.8))
```


## Poisson regression

$$
\begin{align*}
y_i &\sim \mathcal{Poisson}(\lambda_i) \\
\log{\lambda_i} &= \alpha + \beta (x_i - \bar{x})
\end{align*}
$$


### Example: Oceanic tool complexity

```{r}
data(Kline)
d <- Kline %>%
  mutate(log_pop_s = log(population),
         log_pop_s = as.vector(scale(log_pop_s)),
         cid = factor(contact, levels = c("low", "high")))
rm(Kline)
skimr::skim(d)
```


the model is

$$
total\_tools_i \sim \mathcal{Poisson}(\lambda_i) \\
\log{\lambda_i} = \alpha_{cid[i]} + \beta_{cid[i]} \log{log\_pop\_s_i} \\
\alpha_j \sim \mathcal{N}(0, ?) \\
\beta_k \sim \mathcal{N}(0, ?)
$$


#### Calibrating the priors

> Source: https://ggplot2.tidyverse.org/reference/geom_function.html

For the intercept $\alpha_j$ we try


```{r}
# source: https://ggplot2.tidyverse.org/reference/geom_function.html
dist1 <- c("meanlog" = 0, "sdlog" = 10)
dist2 <- c("meanlog" = 3, "sdlog" = 0.5)
p1 <- ggplot(data = data.frame(x = c(0, 100)), aes(x)) +
  geom_function(fun = dlnorm, n = 201, args = list(meanlog = dist1[1], sdlog = dist1[2]),
                size = 1/2) +
  geom_function(fun = dlnorm, n = 201, args = list(meanlog = dist2[1], sdlog = dist2[2]),
                size = 1/2, color = "blue") +
  annotate(geom = "text", x = 5, y = 0.06,
           size = 3, color = "black", hjust = 0, parse = FALSE,
           label = sprintf("dlnormal(%.1f, %.1f)\n mean = %.1f", 
                           dist1[1], dist1[2], dist1[1] + exp(dist1[2]^2)/2)) +
  annotate(geom = "text", x = 35, y = 0.03,
           size = 3, color = "blue", hjust = 0, parse = FALSE,
           label = sprintf("dlnormal(%.1f, %.1f)\n mean = %.1f", 
                           dist2[1], dist2[2], dist2[1] + exp(dist2[2]^2)/2)) +
  scale_x_continuous(breaks = scales::breaks_width(width = 20)) +
  scale_y_continuous(breaks = scales::breaks_width(width = 0.01)) +
  coord_cartesian(xlim = c(0, 100), ylim = c(0, 0.08)) +
  ggthemes::theme_clean() +
  labs(title = "Prior distributions",
       x = expression("mean number of tools" ~ lambda),
       y = "denisty")
p1
```



For the intercept $\beta_k$ we try

```{r}
set.seed(11)

# how many lines would you like?
n <- 100

# simulate and wrangle
df <- tibble(i = seq_len(n),
       a = rnorm(n, mean = 3, sd = 0.5)) %>% 
  mutate(`beta%~%Normal(0*', '*10)`  = rnorm(n, mean = 0 , sd = 10),
         `beta%~%Normal(0*', '*0.2)` = rnorm(n, mean = 0 , sd = 0.2)) %>% 
  pivot_longer(contains("beta"),
               values_to = "b",
               names_to = "prior") %>% 
  expand(nesting(i, a, b, prior),
         x = seq(from = -2, to = 2, length.out = 100))
  
  # plot
ggplot(df, aes(x = x, y = exp(a + b * x), group = i, color = i)) +
  geom_line(size = 1/4, alpha = 2/3) +
  scale_color_paletteer_c(palette = "pals::kovesi.linear_ternary_green_0_46_c42") + 
  coord_cartesian(ylim = c(0, 100)) +
  ggthemes::theme_hc() +
  theme(legend.position = "none") +
  labs(x = "log population (std)", y = "total tools") +
  facet_wrap(~ prior, labeller = label_parsed)
```

#### Model and fit


The model with the priors as explained just above is

$$
total\_tools_i \sim \mathcal{Poisson}(\lambda_i) \\
\log{\lambda_i} = \alpha_{cid[i]} + \beta_{cid[i]} \log{log\_pop\_s_i} \\
\alpha_j \sim \mathcal{N}(3, 0.5) \\
\beta_k \sim \mathcal{N}(0, 0.2)
$$

The fit with intercept only

```{r}
a_file <- here::here("fits", "b11_09.rds")
b11.9 <- readRDS(a_file)
# b11.9 <- brm(data = d,
#              family = poisson,
#              formula = total_tools ~ 1,
#              prior = c(prior(normal(3, 0.5), class = Intercept)),
#              cores = detectCores(), seed = 11)
# b11.9 <- brms::add_criterion(b11.9, criterion = c("waic", "loo"))
# saveRDS(b11.9, file = a_file)
summary(b11.9)
```

and the model with the interaction between population and contact

```{r}
a_file <- here::here("fits", "b11_10.rds")
b11.10 <- readRDS(a_file)
# b11.10 <- brm(data = d,
#              family = poisson,
#              formula = bf(total_tools ~ a + b * log_pop_s,
#                           a + b ~ 0 + cid,
#                           nl = TRUE),
#              prior = c(prior(normal(3, 0.5), nlpar = a),
#                        prior(normal(0, 0.2), nlpar = b)),
#              cores = detectCores(), seed = 11)
# b11.10 <- brms::add_criterion(b11.10, criterion = c("waic", "loo"))
# saveRDS(b11.10, file = a_file)
summary(b11.10)
```

and we compare the LOO

```{r}
loo::loo_compare(b11.9, b11.10, criterion = "loo") %>%
  print(simplify = FALSE)
```

with the model weights

```{r}
model_weights(b11.9, b11.10) %>% 
  round(digits = 2)
```
and we look ate the pareto k since a warning was issued by `add_criterion()`
above

```{r}
loo::loo(b11.10) %>% loo::pareto_k_table()
```

and the details are

```{r}
tibble(culture = d$culture,
       k = b11.10$criteria$loo$diagnostics$pareto_k) %>% 
  arrange(desc(k)) %>% 
  mutate_if(is.double, round, digits = 2)
```
**which shows that Hawai is the outlier and is very influential**.



### Negative binomial (gamma-Poisson) models



### Example: Exposure and the offset



## Multinomial and categorical models




## Summary