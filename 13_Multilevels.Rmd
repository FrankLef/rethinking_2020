```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(rethinking)
library(brms)
library(loo)
library(modelr)
library(simstudy)
library(posterior)
library(scales)
library(dagitty, quietly = TRUE)
library(ggdag, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(ggmcmc, quietly = TRUE)
library(bayesplot, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```


# Multilevel Models {#MLM}


We set the current theme used for plotting

```{r}
theme_set(ggthemes::theme_solarized_2())
# theme_set(
#   ggthemes::theme_solarized_2(light = TRUE) +
#   theme(strip.background = element_rect(fill = "darkgrey"))
#   )
```


```{r}
# data(iris)
# ggplot(iris, aes(x = Petal.Length, y = Sepal.Length, color = Species)) +
#   geom_point() +
#   labs(title = "Iris dataset", subtitle = sprintf("%d lines", nrow(iris)))
```

## Example: Multilevel tadpoles

```{r}
data(reedfrogs)
dataFrogs <- reedfrogs %>%
  mutate(tank = seq_len(nrow(.)),
         tank = factor(tank))
rm(reedfrogs)
skimr::skim(dataFrogs)
```

with the plot of data

```{r}
plotFrogs <- ggplot(dataFrogs, aes(x = as.integer(tank), y = propsurv)) +
  geom_point(color = "sienna") +
  geom_hline(yintercept = 0.8, color = "sienna1", linetype = "dashed") +
  geom_vline(xintercept = c(16.5, 32.5), size = 1/3, color = "sienna1") +
  scale_x_continuous(breaks = c(1, 16, 32, 48)) +
  scale_y_continuous(breaks = scales::breaks_width(width = 0.2),
                     labels = scales::label_percent(accuracy = 1)) +
  annotate(geom = "text",
           x = c(8, 16 + 6, 32 + 8), y = 0,
           label = c("small tanks", "medium tanks", "large tanks"),
           color = "midnightblue") +
  theme(axis.text.x = element_text(size = rel(1))) +
  labs(title = "Tadpole tanks",
       subtitle = sprintf("%d data points", nrow(dataFrogs)),
       x = "tank", y = "proportion survival")
plotFrogs
```



### Example: Multilevel tadpoles - Simple

and the model, without multilevel effect, is

$$
\begin{align*}
surv_i &\sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) &= \alpha_{tank[i]} \\
\alpha_{tank} &\sim \mathcal{N}(0, 1.5)
\end{align*}
$$

and we fit this

```{r}
a_file <- here::here("fits", "b13_01.rds")
b13.1 <- readRDS(file = a_file)
# b13.1 <- brm(
#   data = dataFrogs,
#   family = binomial,
#   surv | trials(density) ~ 0 + tank,
#   prior = c(prior(normal(0, 1.5), class = b)),
#   cores = detectCores(), seed = 13)
# b13.1 <- add_criterion(b13.1, c("loo", "waic"))
# saveRDS(object = b13.1, file = a_file)
summary(b13.1)
```


and visualize the intercepts which correspond to the logit of the probabilities.


```{r}
p <- list()
p$df <- fixef(b13.1) %>%
  as.data.frame() %>%
  select(Estimate) %>%
  mutate(p = gtools::inv.logit(Estimate)) %>%
  pivot_longer(cols = c("Estimate", "p"), names_to = "key") %>%
  mutate(key = if_else(key == "p", "exp_surv_prob", "exp_surv_log-odds"))
# p$df
ggplot(p$df, aes(x = value, fill = key, color = key)) +
  geom_dotplot() +
  scale_fill_manual(values = c("orange1", "orange4")) +
  scale_color_manual(values = c("orange1", "orange4")) +
  scale_y_continuous(breaks = NULL) +
  theme(legend.position = "none") +
  labs(title = "Tank-level intercepts from the no-pooling model",
       x = NULL, y = NULL) +
  facet_wrap(~ key, scales = "free_x")
```



### Example: Multilevel tadpoles - Multilevel

and now the multilevel model

$$
\begin{align*}
surv_i &\sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) &= \alpha_{tank[i]} \\
\alpha_j &\sim \mathcal{N}(\bar{\alpha}, \sigma) \\
\bar{\alpha} &\sim \mathcal{N}(0, 1.5) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

and the fit is as follows.  Note the prior `prior(exponential(0, 1), class = sd)`
*which is parametrized in the standard deviation metric* (Kurtz). It is common
for multilevel software to model the variance metric.  This will be further
explained in chapter 14.


```{r}
a_file <- here::here("fits", "b13_02.rds")
b13.2 <- readRDS(file = a_file)
# b13.2 <- brm(
#   data = dataFrogs,
#   family = binomial,
#   surv | trials(density) ~ 1 + (1 | tank),
#   prior = c(prior(normal(0, 1.5), class = Intercept),
#             prior(exponential(1), class = sd)),
#   cores = detectCores(),
#   sample_prior = TRUE, seed = 13)
# b13.2 <- add_criterion(b13.2, c("loo", "waic"))
# saveRDS(object = b13.2, file = a_file)
summary(b13.2)
```



### Example: Multilevel tadpoles - Comparison

and compare the models

```{r}
loo_compare(b13.1, b13.2, criterion = "waic")
```

and convert the elpd_diif to the waic metric

```{r}
loo_compare(b13.1, b13.2, criterion = "waic") %>%
  as.data.frame() %>%
  mutate(waic_diff = elpd_diff * -2,
         waic_diff_se = se_diff * 2) %>%
  select(elpd_diff, se_diff, waic_diff, waic_diff_se)
```

```{r}
model_weights(b13.1, b13.2, weights = "waic") %>%
  round(digits = 2)
```



### Example: Multilevel tadpoles - Posterior distribution



```{r}
summary(b13.2)
```



This time we don't have a list of intercepts as in `b13.2`.  We have a descripion
of their distribution $\alpha_j \sim \mathcal{N}(\bar{\alpha}, \sigma)$ where
$Intercept = \bar{\alpha}$ and $sd(Intercept) = \sigma$.

The task of getting the posterior is easier with `tidybayes` and `posterior`
than the way McElreath and Kurtz do it.

```{r}
# IMPORTANT: We use the median value, not the mean because of skewed
#            binomial dist. You don't always have to use the mean!
fitted <- list()
fitted <- within(fitted, {
  newdata <- dataFrogs
  data <- epred_draws(b13.2, newdata = newdata) %>%
    as.data.frame() %>%
    select(tank, density, .epred) %>%
    mutate(prop = .epred / density) %>%
    group_by(tank) %>%
    summarize(surv_prop = median(prop))
})
# fitted$data
```

```{r}
plotFrogs +
  geom_point(fitted$data, mapping = aes(x = as.integer(tank), y = surv_prop),
             inherit.aes = FALSE, shape = 1, size = 2, color = "darkorange")
```


First, we take a sampling of size 100 of the 4000 draws from the posterior
sample with `slice_sample(n = 100)`.

Second, to simulate the **distribution** of the logodds values described by the 
`b_Intercept` and `tank_Intercepts` of **each draw** we create a 
sequence of 100 logodds values between -4 and 5 
(based on the acutal range of -2, 3.5 shown just above)
which is done by 
`expand(nesting(iter, b_Intercept, sd_tank__Intercept), x = seq(from = -4, to = 5, length.out = 100))`
and which will result in 10000 lines.

Third, we compute the normal density for each of the 10000 lines using the
`b_Intercept` and `tank_Intercepts` of each line.  The normal density is used
because the model is $\alpha_{tank} \sim \mathcal{N}(0, 5)$ and
$\alpha \sim \mathcal{N}(0, 1)$.  This is done with



```{r}
samples <- list()
samples <- within(samples, {
  data1 <- as_draws_df(b13.2) %>%
    slice_sample(n = 100) %>%
    expand(nesting(.draw, b_Intercept, sd_tank__Intercept),
           x = seq(from = -4, to = 5, length.out = 100)) %>%
    mutate(density = dnorm(x, mean = b_Intercept, sd = sd_tank__Intercept))
  data2 <- as_draws_df(b13.2) %>%
    slice_sample(n = 1000, replace = TRUE) %>%
    mutate(p_logit = rnorm(n(), mean = b_Intercept, sd = sd_tank__Intercept),
           p = gtools::inv.logit(p_logit))
  
  p1 <- ggplot(data1, aes(x = x, y = density, group = .draw)) +
    geom_line(alpha = .2, color = "sienna2") +
    scale_y_continuous(NULL, breaks = NULL) +
    coord_cartesian(xlim = c(-3, 4)) +
    labs(title = "Population survival distribution",
         subtitle = "log-odds scale", x = NULL, y = NULL)
  
  p2 <-  ggplot(data2, aes(x = p)) +
    geom_density(size = 0, fill = "sienna2", color = "sienna2", adjust = 0.1) +
    scale_y_continuous(NULL, breaks = NULL) +
    labs(title = "Probability of survival",
         subtitle = "transformed by the inverse-logit function",
         x = NULL, y = NULL)
})
wrap_plots(samples$p1, samples$p2)
```




## Varying effects


### The model



$$
\begin{align*}
surv_i &\sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) &= \alpha_{pond[i]} \\
\alpha_{pond} &\sim \mathcal{N}(\alpha, \sigma) \\
\alpha &\sim \mathcal{N}(0, 1) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1)
\end{align*}
$$

where we have

* $\alpha$: Average log-odd of the survival rate for entire population of ponds
* $\sigma$: Standard deviation of log-odds of survival among ponds
* $\alpha_{pond}$: vector of individual pond intercept (mean)

### Assign value to the parameters


```{r}
a <- 1.4
sigma <- 1.5
nponds <- 60
set.seed(12)

# must use as.interger because of stan, see overthinking box on p. 366
dsim <-
  tibble(pond = seq_len(nponds),
         ni = rep(as.integer(c(5, 10, 25, 35)), each = nponds/4),
         true_a = rnorm(n = nponds, mean = a, sd = sigma))
glimpse(dsim)
```

and we plot the data to see the real distributions

```{r}
dsim %>%
  mutate(ni = factor(ni)) %>%
  ggplot(aes(x = true_a, y = ni)) +
  tidybayes::stat_halfeye(.width = 0.5, fill = "orange") +
  theme_light() +
  labs(title = "Distribution of log odd of survival by pond")
  
```



### Simulate survivors

The model uses

$$
logit(p_i) = \alpha_{pond[i]} \\
\alpha_{pond} \sim \mathcal{N}(\alpha, \sigma) \\
\alpha \sim \mathcal{N}(0, 1) \\
\sigma \sim \mathcal{HalfCauchy}(0, 1)
$$
therefore

the simulation of $p_i$ must use the logistic function


```{r}
set.seed(12)
dsim <- dsim %>%
  mutate(si = rbinom(n = nrow(dsim), prob = plogis(true_a), size = ni))
dsim
```

### Compute the no-pooling estimates

```{r}
dsim <- dsim %>%
  mutate(p_nopool = si / ni)
dsim
```

### Compute the partial pooling estimates


```{r}
a_file <- here::here("fits", "b12_03.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.3 <- readRDS(file = a_file)  # load the file
# b12.3 <- brm(
#   data = dsim,
#   family = binomial,
#   si | trials(ni) ~ 1 + (1 | pond),
#   prior = c(prior(normal(0, 1), class = Intercept),
#             prior(cauchy(0, 1), class = sd)),
#   iter = 10000, warmup = 1000, chains = 1, cores = 4,
#   seed = 12)
# b12.3 <- add_criterion(b12.3, c("loo", "waic"))
# saveRDS(object = b12.3, file = a_file)
```
which gives this summary

```{r}
summary(b12.3)
```

and we get the informaiton on the level 1, the fixed effect, as follows

```{r}
# fixef(b12.3)
```

The level 2, or random effect is

```{r}
# ranef(b12.3)
```

and the whole thing is obtained with the `fit` which calls the stan data

```{r}
# b12.3$fit
```

We then add the the partially-pooled estimates of the posterior distribution
to the simulated data.

>**Important**: The `coef` gives the coefficients of the posterior distribution.
It reflects all the levels of the multilevel model, that is both the fixed effects,
obtained by `fixef()`, and the random effects, obtained by `ranef()`, on the posterior
ditribution.  In our current model which only has an intercept, it is therefore, also, the
average by pond.

```{r}
p_partpool <- coef(b12.3)$pond[, , ] %>%
  as_tibble() %>%
  transmute(p_partpool = plogis(Estimate))
p_partpool

dsim <- dsim %>%
  bind_cols(p_partpool) %>%
  mutate(p_true = plogis(true_a)) %>%
  mutate(nopool_error = abs(p_nopool - p_true),
         partpool_error = abs(p_partpool - p_true))


glimpse(dsim)
```

and we plot the data

```{r}
# data to create the horizontal summary lines
# we put linetype and color in theis df since they are related and
# avoid overloading the ggplot code.
# Kurtz tend to overload functions . . . 
dfline <- dsim %>%
  select(ni, nopool_error, partpool_error) %>%
  pivot_longer(cols = c("nopool_error", "partpool_error"), 
               names_to = "key", values_to = "value") %>%
  group_by(ni, key) %>%
  summarise(mean_error = mean(value)) %>%
  ungroup() %>%
  mutate(x = case_when(ni == 5 ~ 1,
                       ni == 10 ~ 16,
                       ni == 25 ~ 31,
                       ni == 35 ~ 46,
                       TRUE ~ NA_real_),
         xend = case_when(ni == 5 ~ 15,
                       ni == 10 ~ 30,
                       ni == 25 ~ 45,
                       ni ==  35 ~ 60,
                       TRUE ~ NA_real_),
         linetype = case_when(key == "nopool_error" ~ "solid",
                              key == "partpool_error" ~ "dashed",
                              TRUE ~ as.character(key)),
         color = case_when(key == "nopool_error" ~ "orange2",
                              key == "partpool_error" ~ "black",
                              TRUE ~ as.character(key))
         )
dfline

# the subtitle text
stitle <- "The horizontal axis displays pond number. The vertical axis measures\nthe absolute error in the predicted proportion of survivors, compared to\nthe true value used in the simulation. The higher the point, the worse\nthe estimate. No-pooling shown in orange. Partial pooling shown in black.\nThe orange and dashed black lines show the average error for each kind\nof estimate, across each initial density of tadpoles (pond size). Smaller\nponds produce more error, but the partial pooling estimates are better\non average, especially in smaller ponds."

p <- ggplot(dsim, aes(x = pond)) +
  geom_vline(xintercept = c(15.5, 30.5, 45.4), color = "white", size = 2/3) +
  geom_point(aes(y = nopool_error), color = "orange2") +
  geom_point(aes(y = partpool_error), shape = 1) +
  geom_segment(data = dfline, 
               aes(x = x, xend = xend, 
                   y = mean_error, yend = mean_error), linetype = dfline$linetype,
                   color = dfline$color) +
  annotate("text", x = c(15 - 7.5, 30 - 7.5, 45 - 7.5, 60 - 7.5), y = .45,
           label = c("tiny (5)", "small (10)", "medium (25)", "large (35)")) +
  scale_x_continuous(breaks = c(1, 10, 20, 30, 40, 50, 60)) +
  labs(title = "Estimate error by model type",
       subtitle = stitle,
       y = "absolute error") +
  # theme_light() +
  ggthemes::theme_fivethirtyeight() +
  theme(panel.grid.major = element_blank(),
        plot.subtitle = element_text(size = 10))
p

```


## More than one type of cluster


### Multilevel chimpanzees

#### The model

$$
pull\_left_i \sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) = \alpha + \alpha_{actor[i]} + (\beta_P + \beta_{PC} C_i) P_i \\
\alpha_{actor} \sim \mathcal{N}(0, \sigma_{actor}) \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta_P \sim \mathcal{N}(0, 10) \\
\beta_{PC} \sim \mathcal{N}(0, 10) \\
\sigma_{actor} \sim \mathcal{HalfCauchy}(0, 1)
$$
#### The fit

We load the data

```{r}
data(chimpanzees)
d <- chimpanzees
glimpse(d)
```



```{r}
a_file <- here::here("fits", "b12_04.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.4 <- readRDS(file = a_file)  # load the file
# b12.4 <- brm(
#   data = d,
#   family = binomial,
#   pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + (1 | actor),
#   prior = c(prior(normal(0, 10), class = Intercept),
#             prior(normal(0, 10), class = b),
#             prior(cauchy(0, 1), class = sd)),
#   iter = 5000, warmup = 1000, chains = 4, cores = 4,
#   control = list(adapt_delta = 0.95),
#   seed = 12)
# b12.4 <- add_criterion(b12.4, c("loo", "waic"))
# saveRDS(object = b12.4, file = a_file)
```

the posterior samples is

```{r}
bpost12.4 <- posterior_samples(b12.4)
str(bpost12.4)
```

and we look at the standard deviaiton of the random effect of actor

```{r}
ggplot(bpost12.4, aes(x = sd_actor__Intercept)) +
  tidybayes::stat_halfeye(.width = 0.95, fill = "orange") +
  # scale_y_continuous(breaks = NULL) +
  ggthemes::theme_economist() +
  labs(title = expression(sigma[actor]))
```

### Two types of cluster


#### The model

$$
pull\_left_i \sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) = \alpha + \alpha_{actor[i]} + \alpha_{block[i]} + (\beta_P + \beta_{PC} C_i) P_i \\
\alpha_{actor} \sim \mathcal{N}(0, \sigma_{actor}) \\
\alpha_{block} \sim \mathcal{N}(0, \sigma_{block}) \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta_P \sim \mathcal{N}(0, 10) \\
\beta_{PC} \sim \mathcal{N}(0, 10) \\
\sigma_{actor} \sim \mathcal{HalfCauchy}(0, 1) \\
\sigma_{block} \sim \mathcal{HalfCauchy}(0, 1)
$$

#### The fit

```{r}
a_file <- here::here("fits", "b12_05.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.5 <- readRDS(file = a_file)  # load the file
# b12.5 <- update(
#   b12.4,
#   newdata = d,
#   formula = pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + (1 | actor)  + (1 | block),
#   iter = 6000, warmup = 1000, chains = 4, cores = 4,
#   control = list(adapt_delta = 0.9),
#   seed = 12)
# b12.5 <- add_criterion(b12.5, c("loo", "waic"))
# saveRDS(object = b12.5, file = a_file)
```



## Multilevel posterior predictions


### Posterior prediction for same clusters

Predicting chimp 2 we have

```{r}
chimp <- 2
nd <-
  tibble(prosoc_left = c(0, 1, 0, 1),
         condition   = c(0, 0, 1, 1),
         actor       = chimp)
nd

chimp_2_fitted <-fitted(b12.4, newdata = nd) %>%
  as_tibble() %>%
  mutate(prosoc_left = c(0, 1, 0, 1),
         condition   = c(0, 0, 1, 1),
         prosoc_cond = paste(prosoc_left, condition, sep = "/"),
         prosoc_cond = factor(prosoc_cond, levels = c("0/0", "1/0", "0/1", "1/1")))
chimp_2_fitted
```

and we plot the fitted data

```{r}
# if you want to use `geom_line()` or `geom_ribbon()` with a factor on the x axis,
# you need to code something like `group = 1` in `aes()`
p_fit <- ggplot(chimp_2_fitted, aes(x = prosoc_cond, y = Estimate, group = 1)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "orange", alpha = 0.5) +
  geom_line(color = "blue") +
  coord_cartesian(ylim = c(0.75, 1)) +
  ggthemes:::theme_igray() +
  labs(title = "Chimp # 2", x = NULL, y = NULL)
p_fit
```



and using the average of real data we have

```{r}
chimp_2_raw <- d %>%
  filter(actor == chimp) %>%
    mutate(
      prosoc_cond = paste(prosoc_left, condition, sep = "/"),
      prosoc_cond = factor(prosoc_cond, levels = c("0/0", "1/0", "0/1", "1/1"))) %>%
  group_by(prosoc_left, condition, prosoc_cond) %>%
  summarise(prob = mean(pulled_left)) %>%
  ungroup()
chimp_2_raw
```





## Summary



## Practice
